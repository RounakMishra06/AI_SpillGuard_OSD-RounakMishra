{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b7a5458",
   "metadata": {},
   "source": [
    "# AI SpillGuard Oil Spill Detection - Week 3-4 Implementation\n",
    "\n",
    "## Milestone 3: Week 3-4 Module Implementation\n",
    "\n",
    "**Module 3: Model Development (Segmentation and Classification)**\n",
    "- Design and implement deep learning models like U-Net or CNN-based architectures\n",
    "- Customize input layers to handle single-channel SAR or multi-channel satellite data\n",
    "- Build the segmentation pipeline to predict oil spill regions from raw image inputs\n",
    "\n",
    "**Module 4: Training and Evaluation**\n",
    "- Train the model using training datasets with real-time augmentation and validation\n",
    "- Implement loss functions like Dice Loss and Binary Cross-Entropy\n",
    "- Evaluate the model using metrics such as Accuracy, IoU, Dice Coefficient, Precision, and Recall\n",
    "- Fine-tune hyperparameters based on validation performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7a461f",
   "metadata": {},
   "source": [
    "## Module 3: Model Development (Segmentation and Classification)\n",
    "\n",
    "### Task 3.1: Environment Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f224afcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è Using device: cpu\n",
      "üìÇ train/images/: 20 files\n",
      "üìÇ train/masks/: 20 files\n",
      "üìÇ val/images/: 8 files\n",
      "üìÇ val/masks/: 8 files\n",
      "üìÇ test/images/: 5 files\n",
      "üìÇ test/masks/: 5 files\n"
     ]
    }
   ],
   "source": [
    "# Setup environment and imports\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# Deep learning imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üñ•Ô∏è Using device: {device}\")\n",
    "\n",
    "# Set dataset paths\n",
    "data_root = Path('../data')\n",
    "for split in ['train', 'val', 'test']:\n",
    "    for folder in ['images', 'masks']:\n",
    "        path = data_root / split / folder\n",
    "        count = len(list(path.glob('*.*')))\n",
    "        print(f\"üìÇ {split}/{folder}/: {count} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a94df6",
   "metadata": {},
   "source": [
    "### Task 3.2: Dataset Class Implementation\n",
    "\n",
    "Create a PyTorch dataset for loading oil spill images and masks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db7ecd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OilSpillDataset(Dataset):\n",
    "    \"\"\"Oil Spill segmentation dataset\"\"\"\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.mask_dir = Path(mask_dir)\n",
    "        self.transform = transform\n",
    "        self.image_paths = sorted(list(self.image_dir.glob('*.jpg')))\n",
    "        self.mask_paths = []\n",
    "        for img_path in self.image_paths:\n",
    "            mask_filename = img_path.stem + \".png\"\n",
    "            mask_path = self.mask_dir / mask_filename\n",
    "            if mask_path.exists():\n",
    "                self.mask_paths.append(mask_path)\n",
    "            else:\n",
    "                self.image_paths.remove(img_path)\n",
    "        assert len(self.image_paths) == len(self.mask_paths), \"Mismatch in number of images and masks\"\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        mask_path = self.mask_paths[idx]\n",
    "        image = cv2.imread(str(img_path))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "        mask = (mask > 0).astype(np.float32)\n",
    "        if self.transform is not None:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "            # Ensure mask has shape (1, H, W)\n",
    "            if isinstance(mask, torch.Tensor):\n",
    "                if mask.ndim == 2:\n",
    "                    mask = mask.unsqueeze(0)\n",
    "            else:\n",
    "                if mask.ndim == 2:\n",
    "                    mask = np.expand_dims(mask, axis=0)\n",
    "                mask = torch.from_numpy(mask)\n",
    "        else:\n",
    "            image = image.astype(np.float32) / 255.0\n",
    "            image = torch.from_numpy(image).permute(2, 0, 1)\n",
    "            mask = torch.from_numpy(mask).unsqueeze(0)\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a978831e",
   "metadata": {},
   "source": [
    "### Task 3.3: U-Net Architecture Implementation\n",
    "\n",
    "Implement U-Net architecture for satellite image segmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c781797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 3, 256, 256])\n",
      "Output shape: torch.Size([2, 1, 256, 256])\n",
      "Model parameters: 31,043,521\n",
      "Model moved to cpu\n"
     ]
    }
   ],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"Double Convolution Block for U-Net\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"U-Net architecture for oil spill segmentation\n",
    "    \n",
    "    Paper: \"U-Net: Convolutional Networks for Biomedical Image Segmentation\"\n",
    "    Link: https://arxiv.org/abs/1505.04597\n",
    "    \n",
    "    Modified for oil spill detection with variable input channels.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n",
    "        \"\"\"Initialize U-Net model.\n",
    "        \n",
    "        Args:\n",
    "            in_channels: Number of input channels (3 for RGB, 1 for SAR)\n",
    "            out_channels: Number of output channels (1 for binary segmentation)\n",
    "            features: List of feature dimensions for each level\n",
    "        \"\"\"\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        self.downs = nn.ModuleList()  # Downsampling (encoder) path\n",
    "        self.ups = nn.ModuleList()    # Upsampling (decoder) path\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Encoder / Downsampling path\n",
    "        for feature in features:\n",
    "            self.downs.append(ConvBlock(in_channels, feature))\n",
    "            in_channels = feature\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = ConvBlock(features[-1], features[-1] * 2)\n",
    "        \n",
    "        # Decoder / Upsampling path\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(\n",
    "                nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2)\n",
    "            )\n",
    "            self.ups.append(ConvBlock(feature * 2, feature))\n",
    "        \n",
    "        # Final convolution\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through U-Net\"\"\"\n",
    "        skip_connections = []\n",
    "        \n",
    "        # Encoder path - save skip connections\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "        \n",
    "        # Bottleneck\n",
    "        x = self.bottleneck(x)\n",
    "        \n",
    "        # Reverse skip connections list for decoder path\n",
    "        skip_connections = skip_connections[::-1]\n",
    "        \n",
    "        # Decoder path\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            # Upsampling\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx // 2]\n",
    "            \n",
    "            # Handle cases where dimensions don't match\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = nn.functional.interpolate(\n",
    "                    x, size=skip_connection.shape[2:], mode=\"bilinear\", align_corners=True\n",
    "                )\n",
    "            \n",
    "            # Concatenate with skip connection\n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "            \n",
    "            # Convolution after concatenation\n",
    "            x = self.ups[idx + 1](concat_skip)\n",
    "        \n",
    "        # Final 1x1 convolution for segmentation\n",
    "        return self.final_conv(x)\n",
    "\n",
    "# Test model creation\n",
    "def test_unet(batch_size=2, in_channels=3, out_channels=1):\n",
    "    \"\"\"Test U-Net architecture\"\"\"\n",
    "    x = torch.randn((batch_size, in_channels, 256, 256))\n",
    "    model = UNet(in_channels=in_channels, out_channels=out_channels)\n",
    "    preds = model(x)\n",
    "    print(f\"Input shape: {x.shape}\")\n",
    "    print(f\"Output shape: {preds.shape}\")\n",
    "    \n",
    "    # Calculate model size\n",
    "    model_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Model parameters: {model_params:,}\")\n",
    "    \n",
    "    # Move model to device\n",
    "    model = model.to(device)\n",
    "    print(f\"Model moved to {device}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and test U-Net model\n",
    "model = test_unet(batch_size=2, in_channels=3, out_channels=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a37cefe",
   "metadata": {},
   "source": [
    "### Task 3.4: Loss Functions and Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2757b3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE Loss: 0.8012\n",
      "Dice Loss: 0.4979\n",
      "BCE-Dice Loss: 0.6496\n",
      "IoU: 0.3404\n",
      "Dice: 0.5078\n"
     ]
    }
   ],
   "source": [
    "# Implement specialized loss functions for segmentation\n",
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"Dice Loss for segmentation\"\"\"\n",
    "    \n",
    "    def __init__(self, smooth=1e-5):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        # Flatten predictions and targets\n",
    "        predictions = predictions.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        # Apply sigmoid to predictions for binary segmentation\n",
    "        predictions = torch.sigmoid(predictions)\n",
    "        \n",
    "        # Calculate Dice coefficient\n",
    "        intersection = (predictions * targets).sum()\n",
    "        dice = (2.0 * intersection + self.smooth) / (\n",
    "            predictions.sum() + targets.sum() + self.smooth\n",
    "        )\n",
    "        \n",
    "        return 1 - dice\n",
    "\n",
    "# Combined BCE and Dice Loss for better segmentation results\n",
    "class BCEDiceLoss(nn.Module):\n",
    "    \"\"\"Combined Binary Cross Entropy and Dice Loss\"\"\"\n",
    "    \n",
    "    def __init__(self, bce_weight=0.5, dice_weight=0.5):\n",
    "        super(BCEDiceLoss, self).__init__()\n",
    "        self.bce_weight = bce_weight\n",
    "        self.dice_weight = dice_weight\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss()\n",
    "        self.dice_loss = DiceLoss()\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        bce_loss = self.bce_loss(predictions, targets)\n",
    "        dice_loss = self.dice_loss(predictions, targets)\n",
    "        combined_loss = self.bce_weight * bce_loss + self.dice_weight * dice_loss\n",
    "        return combined_loss\n",
    "\n",
    "# Evaluation metrics\n",
    "def calculate_iou(pred_mask, gt_mask, threshold=0.5, smooth=1e-5):\n",
    "    \"\"\"Calculate IoU (Intersection over Union) metric\n",
    "    \n",
    "    Args:\n",
    "        pred_mask: Predicted mask (after sigmoid)\n",
    "        gt_mask: Ground truth mask\n",
    "        threshold: Threshold for binary prediction\n",
    "        smooth: Smoothing factor to avoid division by zero\n",
    "    \"\"\"\n",
    "    # Apply threshold to get binary prediction\n",
    "    pred_binary = (pred_mask > threshold).float()\n",
    "    \n",
    "    # Calculate intersection and union\n",
    "    intersection = (pred_binary * gt_mask).sum()\n",
    "    union = pred_binary.sum() + gt_mask.sum() - intersection\n",
    "    \n",
    "    # Calculate IoU\n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    \n",
    "    return iou.item()\n",
    "\n",
    "def calculate_dice(pred_mask, gt_mask, threshold=0.5, smooth=1e-5):\n",
    "    \"\"\"Calculate Dice coefficient metric\"\"\"\n",
    "    # Apply threshold to get binary prediction\n",
    "    pred_binary = (pred_mask > threshold).float()\n",
    "    \n",
    "    # Calculate intersection\n",
    "    intersection = (pred_binary * gt_mask).sum()\n",
    "    \n",
    "    # Calculate Dice coefficient\n",
    "    dice = (2.0 * intersection + smooth) / (\n",
    "        pred_binary.sum() + gt_mask.sum() + smooth\n",
    "    )\n",
    "    \n",
    "    return dice.item()\n",
    "\n",
    "def calculate_metrics(pred_masks, gt_masks, threshold=0.5):\n",
    "    \"\"\"Calculate all evaluation metrics\"\"\"\n",
    "    # Apply sigmoid for predictions if they're raw logits\n",
    "    pred_masks = torch.sigmoid(pred_masks)\n",
    "    \n",
    "    batch_size = pred_masks.size(0)\n",
    "    ious = []\n",
    "    dices = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        iou = calculate_iou(pred_masks[i], gt_masks[i], threshold)\n",
    "        dice = calculate_dice(pred_masks[i], gt_masks[i], threshold)\n",
    "        \n",
    "        ious.append(iou)\n",
    "        dices.append(dice)\n",
    "    \n",
    "    # Average metrics over batch\n",
    "    avg_iou = sum(ious) / len(ious)\n",
    "    avg_dice = sum(dices) / len(dices)\n",
    "    \n",
    "    return {\n",
    "        'iou': avg_iou,\n",
    "        'dice': avg_dice\n",
    "    }\n",
    "\n",
    "# Test loss functions\n",
    "def test_loss_functions():\n",
    "    \"\"\"Test loss functions and metrics\"\"\"\n",
    "    # Create dummy predictions and targets\n",
    "    batch_size = 3\n",
    "    h, w = 32, 32\n",
    "    predictions = torch.randn(batch_size, 1, h, w)  # Raw logits\n",
    "    targets = torch.randint(0, 2, (batch_size, 1, h, w)).float()  # Binary masks\n",
    "    \n",
    "    # Apply sigmoid to get probabilities\n",
    "    pred_probs = torch.sigmoid(predictions)\n",
    "    \n",
    "    # Calculate BCE loss\n",
    "    bce_loss = nn.BCEWithLogitsLoss()(predictions, targets)\n",
    "    print(f\"BCE Loss: {bce_loss.item():.4f}\")\n",
    "    \n",
    "    # Calculate Dice loss\n",
    "    dice_loss = DiceLoss()(predictions, targets)\n",
    "    print(f\"Dice Loss: {dice_loss.item():.4f}\")\n",
    "    \n",
    "    # Calculate combined BCE-Dice loss\n",
    "    bce_dice_loss = BCEDiceLoss()(predictions, targets)\n",
    "    print(f\"BCE-Dice Loss: {bce_dice_loss.item():.4f}\")\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    metrics = calculate_metrics(predictions, targets)\n",
    "    print(f\"IoU: {metrics['iou']:.4f}\")\n",
    "    print(f\"Dice: {metrics['dice']:.4f}\")\n",
    "\n",
    "# Run test\n",
    "test_loss_functions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eee8fe5",
   "metadata": {},
   "source": [
    "## Module 4: Training and Evaluation\n",
    "\n",
    "### Task 4.1: Training Function Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3ce41d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders for training and validation\n",
    "def create_dataloaders(batch_size=8):\n",
    "    \"\"\"Create DataLoaders for training and validation\"\"\"\n",
    "    train_dataset = OilSpillDataset(data_root / 'train' / 'images',\n",
    "                                  data_root / 'train' / 'masks',\n",
    "                                  transform=get_training_transforms())\n",
    "    \n",
    "    val_dataset = OilSpillDataset(data_root / 'val' / 'images',\n",
    "                                data_root / 'val' / 'masks',\n",
    "                                transform=get_validation_transforms())\n",
    "    \n",
    "    # Set num_workers=0 to avoid multiprocessing issues on Windows\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, \n",
    "                              num_workers=0, pin_memory=False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, \n",
    "                            num_workers=0, pin_memory=False)\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler=None, \n",
    "                num_epochs=10, device='cpu'):\n",
    "    \"\"\"Train the model\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        train_loader: Training data loader\n",
    "        val_loader: Validation data loader\n",
    "        criterion: Loss function\n",
    "        optimizer: Optimizer\n",
    "        scheduler: Learning rate scheduler (optional)\n",
    "        num_epochs: Number of epochs to train\n",
    "        device: Device to train on ('cuda' or 'cpu')\n",
    "    \"\"\"\n",
    "    # Initialize tracking variables\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'val_iou': [],\n",
    "        'val_dice': []\n",
    "    }\n",
    "    \n",
    "    best_dice = 0.0\n",
    "    \n",
    "    # Loop over epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 15)\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for batch_idx, (images, masks) in enumerate(train_loader):\n",
    "            # Ensure masks have shape [B, 1, H, W]\n",
    "            if masks.ndim == 3:\n",
    "                masks = masks.unsqueeze(1)\n",
    "            # Move to device\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update loss\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            # Print progress\n",
    "            if (batch_idx + 1) % 5 == 0 or (batch_idx + 1) == len(train_loader):\n",
    "                print(f\"Batch {batch_idx+1}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        # Calculate average training loss\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_ious = []\n",
    "        val_dices = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                # Ensure masks have shape [B, 1, H, W]\n",
    "                if masks.ndim == 3:\n",
    "                    masks = masks.unsqueeze(1)\n",
    "                # Move to device\n",
    "                images = images.to(device)\n",
    "                masks = masks.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "                \n",
    "                # Update loss\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                \n",
    "                # Calculate metrics\n",
    "                metrics = calculate_metrics(outputs, masks)\n",
    "                val_ious.append(metrics['iou'])\n",
    "                val_dices.append(metrics['dice'])\n",
    "        \n",
    "        # Calculate average validation metrics\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_iou = sum(val_ious) / len(val_ious) if val_ious else 0.0\n",
    "        val_dice = sum(val_dices) / len(val_dices) if val_dices else 0.0\n",
    "        \n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_iou'].append(val_iou)\n",
    "        history['val_dice'].append(val_dice)\n",
    "        \n",
    "        # Update learning rate scheduler if provided\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_loss)\n",
    "        \n",
    "        # Print epoch results\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "              f\"Train Loss: {train_loss:.4f}, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, \"\n",
    "              f\"Val IoU: {val_iou:.4f}, \"\n",
    "              f\"Val Dice: {val_dice:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_dice > best_dice:\n",
    "            best_dice = val_dice\n",
    "            print(f\"New best model with Dice: {best_dice:.4f}!\")\n",
    "            # Save model checkpoint\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_dice': best_dice,\n",
    "                'val_iou': val_iou,\n",
    "            }, '../models/best_model.pth')\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0581b8f1",
   "metadata": {},
   "source": [
    "### Task 4.2: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f311e08",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_training_transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m OUT_CHANNELS = \u001b[32m1\u001b[39m  \u001b[38;5;66;03m# Binary segmentation\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Create dataloaders\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m train_loader, val_loader = \u001b[43mcreate_dataloaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining batches: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mValidation batches: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(val_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mcreate_dataloaders\u001b[39m\u001b[34m(batch_size)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_dataloaders\u001b[39m(batch_size=\u001b[32m8\u001b[39m):\n\u001b[32m      3\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create DataLoaders for training and validation\"\"\"\u001b[39;00m\n\u001b[32m      4\u001b[39m     train_dataset = OilSpillDataset(data_root / \u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m / \u001b[33m'\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      5\u001b[39m                                   data_root / \u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m / \u001b[33m'\u001b[39m\u001b[33mmasks\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m                                   transform=\u001b[43mget_training_transforms\u001b[49m())\n\u001b[32m      8\u001b[39m     val_dataset = OilSpillDataset(data_root / \u001b[33m'\u001b[39m\u001b[33mval\u001b[39m\u001b[33m'\u001b[39m / \u001b[33m'\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      9\u001b[39m                                 data_root / \u001b[33m'\u001b[39m\u001b[33mval\u001b[39m\u001b[33m'\u001b[39m / \u001b[33m'\u001b[39m\u001b[33mmasks\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     10\u001b[39m                                 transform=get_validation_transforms())\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# Set num_workers=0 to avoid multiprocessing issues on Windows\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'get_training_transforms' is not defined"
     ]
    }
   ],
   "source": [
    "# Create directory for model checkpoints\n",
    "Path('../models').mkdir(exist_ok=True)\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 1e-3\n",
    "NUM_EPOCHS = 5  # Reduced for demo\n",
    "IN_CHANNELS = 3  # RGB images\n",
    "OUT_CHANNELS = 1  # Binary segmentation\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader, val_loader = create_dataloaders(batch_size=BATCH_SIZE)\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n",
    "\n",
    "# Create model\n",
    "model = UNet(in_channels=IN_CHANNELS, out_channels=OUT_CHANNELS)\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = BCEDiceLoss(bce_weight=0.5, dice_weight=0.5)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Learning rate scheduler (fixed verbose parameter)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.1, patience=3\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"üöÄ Starting model training...\")\n",
    "model, history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    device=device\n",
    ")\n",
    "print(\"‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb342bc",
   "metadata": {},
   "source": [
    "### Task 4.3: Plot Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ee18c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training history with loss and metrics\"\"\"\n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # Plot loss curves\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    # Loss plot\n",
    "    axes[0].plot(epochs, history['train_loss'], 'b-', label='Training Loss')\n",
    "    axes[0].plot(epochs, history['val_loss'], 'r-', label='Validation Loss')\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].set_xlabel('Epochs')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # IoU plot\n",
    "    axes[1].plot(epochs, history['val_iou'], 'g-', label='Validation IoU')\n",
    "    axes[1].set_title('Validation IoU')\n",
    "    axes[1].set_xlabel('Epochs')\n",
    "    axes[1].set_ylabel('IoU')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    # Dice plot\n",
    "    axes[2].plot(epochs, history['val_dice'], 'c-', label='Validation Dice')\n",
    "    axes[2].set_title('Validation Dice Coefficient')\n",
    "    axes[2].set_xlabel('Epochs')\n",
    "    axes[2].set_ylabel('Dice Coefficient')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print final metrics\n",
    "    print(f\"Best validation IoU: {max(history['val_iou']):.4f}\")\n",
    "    print(f\"Best validation Dice: {max(history['val_dice']):.4f}\")\n",
    "\n",
    "# Plot training history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7958e69",
   "metadata": {},
   "source": [
    "### Task 4.4: Model Evaluation and Prediction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6078bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_model():\n",
    "    \"\"\"Load the best model checkpoint\"\"\"\n",
    "    # Create a new model instance\n",
    "    model = UNet(in_channels=IN_CHANNELS, out_channels=OUT_CHANNELS).to(device)\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load('../models/best_model.pth')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    print(f\"Loaded best model from epoch {checkpoint['epoch']+1} \")\n",
    "    print(f\"Validation Dice: {checkpoint['val_dice']:.4f}, Validation IoU: {checkpoint['val_iou']:.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def visualize_predictions(model, dataloader, num_samples=5):\n",
    "    \"\"\"Visualize model predictions\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get samples from dataloader\n",
    "    samples = []\n",
    "    for images, masks in dataloader:\n",
    "        batch_size = images.size(0)\n",
    "        for i in range(batch_size):\n",
    "            samples.append((images[i], masks[i]))\n",
    "        if len(samples) >= num_samples:\n",
    "            break\n",
    "    \n",
    "    # Select random samples\n",
    "    samples = random.sample(samples, min(num_samples, len(samples)))\n",
    "    \n",
    "    # Visualize predictions\n",
    "    fig, axes = plt.subplots(num_samples, 4, figsize=(20, num_samples * 5))\n",
    "    fig.suptitle('Oil Spill Detection Results', fontsize=16)\n",
    "    \n",
    "    # Column titles\n",
    "    titles = ['Input Image', 'Ground Truth Mask', 'Predicted Mask', 'Overlay']\n",
    "    for j, title in enumerate(titles):\n",
    "        axes[0, j].set_title(title, fontsize=14)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (image, mask) in enumerate(samples):\n",
    "            # Make prediction\n",
    "            image_tensor = image.unsqueeze(0).to(device)  # Add batch dimension\n",
    "            output = model(image_tensor)\n",
    "            pred_mask = torch.sigmoid(output).squeeze().cpu().numpy()\n",
    "            pred_binary = (pred_mask > 0.5).astype(np.float32)\n",
    "            \n",
    "            # Convert tensors to numpy for visualization\n",
    "            if has_albumentation:\n",
    "                # Denormalize image\n",
    "                image_np = image.cpu().numpy().transpose(1, 2, 0)  # (C,H,W) -> (H,W,C)\n",
    "                std = np.array([0.229, 0.224, 0.225])\n",
    "                mean = np.array([0.485, 0.456, 0.406])\n",
    "                image_np = image_np * std + mean\n",
    "                image_np = np.clip(image_np, 0, 1)\n",
    "            else:\n",
    "                image_np = image.cpu().numpy().transpose(1, 2, 0)  # (C,H,W) -> (H,W,C)\n",
    "            \n",
    "            mask_np = mask.squeeze().cpu().numpy()  # (1,H,W) -> (H,W)\n",
    "            \n",
    "            # Create overlay\n",
    "            overlay = image_np.copy()\n",
    "            overlay[pred_binary > 0.5] = [1, 0, 0]  # Red for predicted oil spill\n",
    "            \n",
    "            # Plot results\n",
    "            axes[i, 0].imshow(image_np)\n",
    "            axes[i, 0].set_xticks([])\n",
    "            axes[i, 0].set_yticks([])\n",
    "            \n",
    "            axes[i, 1].imshow(mask_np, cmap='gray')\n",
    "            axes[i, 1].set_xticks([])\n",
    "            axes[i, 1].set_yticks([])\n",
    "            \n",
    "            axes[i, 2].imshow(pred_binary, cmap='gray')\n",
    "            axes[i, 2].set_xticks([])\n",
    "            axes[i, 2].set_yticks([])\n",
    "            \n",
    "            axes[i, 3].imshow(overlay)\n",
    "            axes[i, 3].set_xticks([])\n",
    "            axes[i, 3].set_yticks([])\n",
    "            \n",
    "            # Calculate and display metrics\n",
    "            iou = calculate_iou(torch.tensor(pred_binary), torch.tensor(mask_np))\n",
    "            dice = calculate_dice(torch.tensor(pred_binary), torch.tensor(mask_np))\n",
    "            axes[i, 3].set_xlabel(f\"IoU: {iou:.4f}, Dice: {dice:.4f}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.show()\n",
    "\n",
    "# Load best model and evaluate\n",
    "try:\n",
    "    best_model = load_best_model()\n",
    "    \n",
    "    # Create test dataset\n",
    "    test_dataset = OilSpillDataset(data_root / 'test' / 'images',\n",
    "                                  data_root / 'test' / 'masks',\n",
    "                                  transform=get_validation_transforms())\n",
    "    \n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "    \n",
    "    # Visualize predictions\n",
    "    visualize_predictions(best_model, test_loader, num_samples=5)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è Best model checkpoint not found. Please train the model first.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error loading model: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e524ad3",
   "metadata": {},
   "source": [
    "### Task 4.5: Model Fine-tuning and Hyperparameter Optimization\n",
    "\n",
    "After initial training, we can experiment with hyperparameter tuning to improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6933db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning experiments\n",
    "def run_hyperparameter_experiment(experiment_name, params):\n",
    "    \"\"\"Run a hyperparameter experiment\"\"\"\n",
    "    print(f\"üß™ Running experiment: {experiment_name}\")\n",
    "    print(f\"Parameters: {params}\")\n",
    "    \n",
    "    # Create model with specified parameters\n",
    "    model = UNet(in_channels=params['in_channels'], \n",
    "                out_channels=params['out_channels'],\n",
    "                features=params.get('features', [64, 128, 256, 512]))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = BCEDiceLoss(\n",
    "        bce_weight=params.get('bce_weight', 0.5),\n",
    "        dice_weight=params.get('dice_weight', 0.5)\n",
    "    )\n",
    "    \n",
    "    # Optimizer\n",
    "    if params['optimizer'] == 'adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "    elif params['optimizer'] == 'sgd':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=params['learning_rate'], momentum=0.9)\n",
    "    else:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.1, patience=3, verbose=True\n",
    "    )\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader, val_loader = create_dataloaders(batch_size=params['batch_size'])\n",
    "    \n",
    "    # Train the model\n",
    "    model, history = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        num_epochs=params['num_epochs'],\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Save experiment results\n",
    "    experiment_dir = Path(f\"../experiments/{experiment_name}\")\n",
    "    experiment_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save model\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'params': params,\n",
    "        'history': history,\n",
    "        'best_dice': max(history['val_dice']),\n",
    "        'best_iou': max(history['val_iou']),\n",
    "    }, experiment_dir / 'model.pth')\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    return model, history, max(history['val_dice']), max(history['val_iou'])\n",
    "\n",
    "# Define experiments to run\n",
    "# Uncomment to run hyperparameter tuning\n",
    "\"\"\"\n",
    "experiments = [\n",
    "    {\n",
    "        'name': 'baseline',\n",
    "        'params': {\n",
    "            'in_channels': 3,\n",
    "            'out_channels': 1,\n",
    "            'batch_size': 8,\n",
    "            'learning_rate': 1e-3,\n",
    "            'optimizer': 'adam',\n",
    "            'bce_weight': 0.5,\n",
    "            'dice_weight': 0.5,\n",
    "            'num_epochs': 15,\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'smaller_lr',\n",
    "        'params': {\n",
    "            'in_channels': 3,\n",
    "            'out_channels': 1,\n",
    "            'batch_size': 8,\n",
    "            'learning_rate': 1e-4,\n",
    "            'optimizer': 'adam',\n",
    "            'bce_weight': 0.5,\n",
    "            'dice_weight': 0.5,\n",
    "            'num_epochs': 15,\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'more_dice_weight',\n",
    "        'params': {\n",
    "            'in_channels': 3,\n",
    "            'out_channels': 1,\n",
    "            'batch_size': 8,\n",
    "            'learning_rate': 1e-3,\n",
    "            'optimizer': 'adam',\n",
    "            'bce_weight': 0.3,\n",
    "            'dice_weight': 0.7,\n",
    "            'num_epochs': 15,\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "# Create experiments directory\n",
    "Path('../experiments').mkdir(exist_ok=True)\n",
    "\n",
    "# Run experiments\n",
    "results = {}\n",
    "for experiment in experiments:\n",
    "    model, history, best_dice, best_iou = run_hyperparameter_experiment(\n",
    "        experiment['name'], experiment['params']\n",
    "    )\n",
    "    results[experiment['name']] = {\n",
    "        'best_dice': best_dice,\n",
    "        'best_iou': best_iou,\n",
    "        'params': experiment['params']\n",
    "    }\n",
    "\n",
    "# Print experiment results\n",
    "print(\"\\nüìä Experiment Results:\")\n",
    "for name, result in results.items():\n",
    "    print(f\"Experiment: {name}\")\n",
    "    print(f\"Best Dice: {result['best_dice']:.4f}, Best IoU: {result['best_iou']:.4f}\")\n",
    "    print(f\"Learning Rate: {result['params']['learning_rate']}\")\n",
    "    print(f\"BCE Weight: {result['params']['bce_weight']}, Dice Weight: {result['params']['dice_weight']}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Find best experiment\n",
    "best_experiment = max(results.items(), key=lambda x: x[1]['best_dice'])\n",
    "print(f\"‚ú® Best experiment: {best_experiment[0]} with Dice: {best_experiment[1]['best_dice']:.4f}\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n‚úÖ Module 3 and Module 4 complete! You have successfully implemented:\")\n",
    "print(\"‚úì U-Net architecture for oil spill segmentation\")\n",
    "print(\"‚úì Data loading pipeline with augmentation\")\n",
    "print(\"‚úì Loss functions (BCE-Dice) and evaluation metrics (IoU, Dice)\")\n",
    "print(\"‚úì Model training and evaluation pipeline\")\n",
    "print(\"‚úì Hyperparameter tuning framework\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0945284a",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "In this notebook, we successfully implemented Weeks 3-4 requirements for the AI SpillGuard Oil Spill Detection project:\n",
    "\n",
    "1. **Module 3: Model Development (Segmentation and Classification)**\n",
    "   - Designed and implemented U-Net architecture for oil spill segmentation\n",
    "   - Customized input layers to handle satellite imagery\n",
    "   - Built complete segmentation pipeline\n",
    "\n",
    "2. **Module 4: Training and Evaluation**\n",
    "   - Implemented training with real-time augmentation\n",
    "   - Created custom loss functions (BCE, Dice, BCE-Dice)\n",
    "   - Added comprehensive evaluation metrics (IoU, Dice)\n",
    "   - Created framework for hyperparameter optimization\n",
    "\n",
    "**Next steps:**\n",
    "- Deploy model for real-time oil spill detection\n",
    "- Implement additional CNN architectures for comparison (DeepLabV3+, SegNet)\n",
    "- Add post-processing techniques to improve segmentation accuracy\n",
    "- Optimize model for edge deployment on marine vessels or satellites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7b5fa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import albumentations as A\n",
    "    from albumentations.pytorch import ToTensorV2\n",
    "    has_albumentation = True\n",
    "    \n",
    "    def get_training_transforms():\n",
    "        return A.Compose([\n",
    "            A.Resize(256, 256),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.RandomBrightnessContrast(p=0.2),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    \n",
    "    def get_validation_transforms():\n",
    "        return A.Compose([\n",
    "            A.Resize(256, 256),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "except ImportError:\n",
    "    import torchvision.transforms as T\n",
    "    has_albumentation = False\n",
    "    \n",
    "    def get_training_transforms():\n",
    "        return T.Compose([\n",
    "            T.ToPILImage(),\n",
    "            T.Resize((256, 256)),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.RandomVerticalFlip(),\n",
    "            T.ToTensor(),\n",
    "        ])\n",
    "    \n",
    "    def get_validation_transforms():\n",
    "        return T.Compose([\n",
    "            T.ToPILImage(),\n",
    "            T.Resize((256, 256)),\n",
    "            T.ToTensor(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1d147e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631f85e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
